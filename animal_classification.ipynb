{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "K2RrWfDrbEWk"
      },
      "outputs": [],
      "source": [
        "# 데이터셋 로더 설정\n",
        "\n",
        "from torchvision import transforms, datasets\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "transform = transforms.Compose([\n",
        "        transforms.Resize((200,200)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "train_dataset = datasets.ImageFolder(root='/content/drive/MyDrive/image_classification_dataset/train', transform=transform)\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# resnet50 정의\n",
        "\n",
        "class ResidualBlock(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, stride=1):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "        self.conv3 = nn.Conv2d(out_channels, out_channels * self.expansion, kernel_size=1, stride=1, padding=0, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(out_channels * self.expansion)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_channels != out_channels * self.expansion:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_channels, out_channels * self.expansion, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(out_channels * self.expansion)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = torch.relu(self.bn1(self.conv1(x)))\n",
        "        out = torch.relu(self.bn2(self.conv2(out)))\n",
        "        out = self.bn3(self.conv3(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = torch.relu(out)\n",
        "        return out\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, layers, num_classes=1000):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_channels = 64\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.layer1 = self.make_layer(block, 64, layers[0], stride=1)\n",
        "        self.layer2 = self.make_layer(block, 128, layers[1], stride=2)\n",
        "        self.layer3 = self.make_layer(block, 256, layers[2], stride=2)\n",
        "        self.layer4 = self.make_layer(block, 512, layers[3], stride=2)\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
        "\n",
        "    def make_layer(self, block, out_channels, blocks, stride):\n",
        "        layers = []\n",
        "        layers.append(block(self.in_channels, out_channels, stride))\n",
        "        self.in_channels = out_channels * block.expansion\n",
        "        for _ in range(1, blocks):\n",
        "            layers.append(block(self.in_channels, out_channels))\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = torch.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = self.avg_pool(out)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.fc(out)\n",
        "        return out\n",
        "\n",
        "def resnet50(num_classes=1000):\n",
        "    return ResNet(ResidualBlock, [3, 4, 6, 3], num_classes)\n",
        "\n",
        "resnet50_model = resnet50()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# 모델 정의\n",
        "from torchvision.models import resnet50\n",
        "\n",
        "class CustomResNet(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(CustomResNet, self).__init__()\n",
        "        self.resnet = resnet50(pretrained=False)\n",
        "        in_features = self.resnet.fc.in_features\n",
        "        self.resnet.fc = nn.Linear(in_features, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.resnet(x)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "#animalCF = CustomResNet(num_classes=10).to(device)\n",
        "animalCF = resnet50().to(device)"
      ],
      "metadata": {
        "id": "YHpCeNkVet6_"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 훈련\n",
        "\n",
        "import torch.optim as optim\n",
        "\n",
        "animalCF.train()\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(animalCF.parameters(), lr = 0.001, momentum=0.9)\n",
        "epochs = 100\n",
        "\n",
        "for ep in range(epochs):\n",
        "  running_loss = 0.0\n",
        "  batch_count = 0\n",
        "  for imgs, lbls in train_loader:\n",
        "    batch_count += 1\n",
        "    imgs = imgs.to(device)\n",
        "    lbls = lbls.to(device)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    out = animalCF(imgs)\n",
        "    loss = criterion(out, lbls)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    #print(f\"{batch_count} batch loss: {loss.item()}\")\n",
        "    running_loss += loss.item()\n",
        "\n",
        "  print(f\"Epoch {ep+1}, Loss: {running_loss/len(train_loader):.4f}\")\n",
        "\n",
        "torch.save(animalCF.state_dict(), './model_weights.pth')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FLXAXN69rlPE",
        "outputId": "71fd4b72-5fbb-46cf-a39a-207cdcabad97"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 3.1482\n",
            "Epoch 2, Loss: 1.8228\n",
            "Epoch 3, Loss: 1.8215\n",
            "Epoch 4, Loss: 1.8101\n",
            "Epoch 5, Loss: 1.7969\n",
            "Epoch 6, Loss: 1.8156\n",
            "Epoch 7, Loss: 1.7907\n",
            "Epoch 8, Loss: 1.7989\n",
            "Epoch 9, Loss: 1.7996\n",
            "Epoch 10, Loss: 1.8034\n",
            "Epoch 11, Loss: 1.7574\n",
            "Epoch 12, Loss: 1.7355\n",
            "Epoch 13, Loss: 1.7816\n",
            "Epoch 14, Loss: 1.7457\n",
            "Epoch 15, Loss: 1.7381\n",
            "Epoch 16, Loss: 1.6908\n",
            "Epoch 17, Loss: 1.6921\n",
            "Epoch 18, Loss: 1.7150\n",
            "Epoch 19, Loss: 1.6920\n",
            "Epoch 20, Loss: 1.6903\n",
            "Epoch 21, Loss: 1.6198\n",
            "Epoch 22, Loss: 1.6167\n",
            "Epoch 23, Loss: 1.5811\n",
            "Epoch 24, Loss: 1.5973\n",
            "Epoch 25, Loss: 1.5541\n",
            "Epoch 26, Loss: 1.5499\n",
            "Epoch 27, Loss: 1.5319\n",
            "Epoch 28, Loss: 1.5658\n",
            "Epoch 29, Loss: 1.5363\n",
            "Epoch 30, Loss: 1.5436\n",
            "Epoch 31, Loss: 1.5390\n",
            "Epoch 32, Loss: 1.4732\n",
            "Epoch 33, Loss: 1.4245\n",
            "Epoch 34, Loss: 1.4357\n",
            "Epoch 35, Loss: 1.3794\n",
            "Epoch 36, Loss: 1.3655\n",
            "Epoch 37, Loss: 1.3396\n",
            "Epoch 38, Loss: 1.2850\n",
            "Epoch 39, Loss: 1.2940\n",
            "Epoch 40, Loss: 1.2842\n",
            "Epoch 41, Loss: 1.2402\n",
            "Epoch 42, Loss: 1.1895\n",
            "Epoch 43, Loss: 1.1651\n",
            "Epoch 44, Loss: 1.1238\n",
            "Epoch 45, Loss: 1.0768\n",
            "Epoch 46, Loss: 0.9957\n",
            "Epoch 47, Loss: 0.9615\n",
            "Epoch 48, Loss: 0.9074\n",
            "Epoch 49, Loss: 0.8383\n",
            "Epoch 50, Loss: 0.8445\n",
            "Epoch 51, Loss: 0.7357\n",
            "Epoch 52, Loss: 0.7192\n",
            "Epoch 53, Loss: 0.6737\n",
            "Epoch 54, Loss: 0.6769\n",
            "Epoch 55, Loss: 0.6201\n",
            "Epoch 56, Loss: 0.5826\n",
            "Epoch 57, Loss: 0.4711\n",
            "Epoch 58, Loss: 0.4686\n",
            "Epoch 59, Loss: 0.4672\n",
            "Epoch 60, Loss: 0.3340\n",
            "Epoch 61, Loss: 0.2912\n",
            "Epoch 62, Loss: 0.2744\n",
            "Epoch 63, Loss: 0.2387\n",
            "Epoch 64, Loss: 0.2028\n",
            "Epoch 65, Loss: 0.1575\n",
            "Epoch 66, Loss: 0.1349\n",
            "Epoch 67, Loss: 0.1231\n",
            "Epoch 68, Loss: 0.0810\n",
            "Epoch 69, Loss: 0.0585\n",
            "Epoch 70, Loss: 0.0528\n",
            "Epoch 71, Loss: 0.0580\n",
            "Epoch 72, Loss: 0.0528\n",
            "Epoch 73, Loss: 0.0373\n",
            "Epoch 74, Loss: 0.0381\n",
            "Epoch 75, Loss: 0.0499\n",
            "Epoch 76, Loss: 0.0438\n",
            "Epoch 77, Loss: 0.0330\n",
            "Epoch 78, Loss: 0.0508\n",
            "Epoch 79, Loss: 0.0433\n",
            "Epoch 80, Loss: 0.0204\n",
            "Epoch 81, Loss: 0.0251\n",
            "Epoch 82, Loss: 0.0242\n",
            "Epoch 83, Loss: 0.0290\n",
            "Epoch 84, Loss: 0.0397\n",
            "Epoch 85, Loss: 0.0322\n",
            "Epoch 86, Loss: 0.0193\n",
            "Epoch 87, Loss: 0.0165\n",
            "Epoch 88, Loss: 0.0185\n",
            "Epoch 89, Loss: 0.0125\n",
            "Epoch 90, Loss: 0.0106\n",
            "Epoch 91, Loss: 0.0126\n",
            "Epoch 92, Loss: 0.0201\n",
            "Epoch 93, Loss: 0.0171\n",
            "Epoch 94, Loss: 0.0181\n",
            "Epoch 95, Loss: 0.0105\n",
            "Epoch 96, Loss: 0.0066\n",
            "Epoch 97, Loss: 0.0068\n",
            "Epoch 98, Loss: 0.0057\n",
            "Epoch 99, Loss: 0.0055\n",
            "Epoch 100, Loss: 0.0179\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 테스트\n",
        "\n",
        "test_dataset = datasets.ImageFolder(root='/content/drive/MyDrive/image_classification_dataset/test', transform=transform)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "animalCF = resnet50().to(device)\n",
        "animalCF.load_state_dict(torch.load('./model_weights.pth'))\n",
        "animalCF.eval()\n",
        "\n",
        "total = 0\n",
        "correct = 0\n",
        "with torch.no_grad():\n",
        "    for imgs, lbls in test_loader:\n",
        "        imgs = imgs.to(device)\n",
        "        lbls = lbls.to(device)\n",
        "        out = animalCF(imgs)\n",
        "        _, predicted = torch.max(out, 1)\n",
        "        total += lbls.size(0)\n",
        "        correct += (predicted == lbls).sum().item()\n",
        "\n",
        "print(f\"Accuracy : {100*correct/total}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CBWXUK2QLsm_",
        "outputId": "948c48f0-b8ee-4e89-8003-e8f2fdc39784"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy : 42.833333333333336%\n"
          ]
        }
      ]
    }
  ]
}
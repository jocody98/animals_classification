{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "K2RrWfDrbEWk"
      },
      "outputs": [],
      "source": [
        "# 데이터셋 로더 설정\n",
        "\n",
        "from torchvision import transforms, datasets\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "transform = transforms.Compose([\n",
        "        transforms.Resize((200,200)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "train_dataset = datasets.ImageFolder(root='/content/drive/MyDrive/image_classification_dataset/train', transform=transform)\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# resnet50 정의\n",
        "\n",
        "class ResidualBlock(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, stride=1):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "        self.conv3 = nn.Conv2d(out_channels, out_channels * self.expansion, kernel_size=1, stride=1, padding=0, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(out_channels * self.expansion)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_channels != out_channels * self.expansion:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_channels, out_channels * self.expansion, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(out_channels * self.expansion)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = torch.relu(self.bn1(self.conv1(x)))\n",
        "        out = torch.relu(self.bn2(self.conv2(out)))\n",
        "        out = self.bn3(self.conv3(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = torch.relu(out)\n",
        "        return out\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, layers, num_classes=1000):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_channels = 64\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.layer1 = self.make_layer(block, 64, layers[0], stride=1)\n",
        "        self.layer2 = self.make_layer(block, 128, layers[1], stride=2)\n",
        "        self.layer3 = self.make_layer(block, 256, layers[2], stride=2)\n",
        "        self.layer4 = self.make_layer(block, 512, layers[3], stride=2)\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
        "\n",
        "    def make_layer(self, block, out_channels, blocks, stride):\n",
        "        layers = []\n",
        "        layers.append(block(self.in_channels, out_channels, stride))\n",
        "        self.in_channels = out_channels * block.expansion\n",
        "        for _ in range(1, blocks):\n",
        "            layers.append(block(self.in_channels, out_channels))\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = torch.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = self.avg_pool(out)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.fc(out)\n",
        "        return out\n",
        "\n",
        "def resnet50(num_classes=1000):\n",
        "    return ResNet(ResidualBlock, [3, 4, 6, 3], num_classes)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# 모델 정의\n",
        "from torchvision.models import resnet50\n",
        "\n",
        "class CustomResNet(nn.Module):\n",
        "    def __init__(self, num_classes=6):\n",
        "        super(CustomResNet, self).__init__()\n",
        "        self.resnet = resnet50(pretrained=True)\n",
        "        in_features = self.resnet.fc.in_features\n",
        "        self.resnet.fc = nn.Linear(in_features, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.resnet(x)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "animalCF = CustomResNet(num_classes=6).to(device)\n",
        "#animalCF = resnet50(num_classes=6).to(device)"
      ],
      "metadata": {
        "id": "YHpCeNkVet6_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10027414-84bd-4484-fc41-bbb1b7832594"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 훈련\n",
        "\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "\n",
        "animalCF.train()\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(animalCF.parameters(), lr = 0.001, momentum=0.9)\n",
        "#scheduler = lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
        "epochs = 10\n",
        "\n",
        "for ep in range(epochs):\n",
        "  running_loss = 0.0\n",
        "  batch_count = 0\n",
        "  for imgs, lbls in train_loader:\n",
        "    batch_count += 1\n",
        "    imgs = imgs.to(device)\n",
        "    lbls = lbls.to(device)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    out = animalCF(imgs)\n",
        "    loss = criterion(out, lbls)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    #print(f\"{batch_count} batch loss: {loss.item()}\")\n",
        "    running_loss += loss.item()\n",
        "\n",
        "  #scheduler.step()\n",
        "  print(f\"Epoch {ep+1}, Loss: {running_loss/len(train_loader):.4f}\")\n",
        "\n",
        "torch.save(animalCF.state_dict(), './model_weights.pth')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FLXAXN69rlPE",
        "outputId": "d05ce2af-043e-41ac-e950-9e3ecd00c397"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 1.4746\n",
            "Epoch 2, Loss: 0.5990\n",
            "Epoch 3, Loss: 0.2771\n",
            "Epoch 4, Loss: 0.1646\n",
            "Epoch 5, Loss: 0.1143\n",
            "Epoch 6, Loss: 0.0869\n",
            "Epoch 7, Loss: 0.0659\n",
            "Epoch 8, Loss: 0.0516\n",
            "Epoch 9, Loss: 0.0379\n",
            "Epoch 10, Loss: 0.0308\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 테스트\n",
        "\n",
        "test_dataset = datasets.ImageFolder(root='/content/drive/MyDrive/image_classification_dataset/test', transform=transform)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "animalCF = CustomResNet(num_classes=6).to(device)\n",
        "animalCF.load_state_dict(torch.load('./model_weights.pth'))\n",
        "animalCF.eval()\n",
        "\n",
        "total = 0\n",
        "correct = 0\n",
        "with torch.no_grad():\n",
        "    for imgs, lbls in test_loader:\n",
        "        imgs = imgs.to(device)\n",
        "        lbls = lbls.to(device)\n",
        "        out = animalCF(imgs)\n",
        "        _, predicted = torch.max(out, 1)\n",
        "        total += lbls.size(0)\n",
        "        correct += (predicted == lbls).sum().item()\n",
        "\n",
        "print(f\"Accuracy : {100*correct/total}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CBWXUK2QLsm_",
        "outputId": "62fdb731-8024-459a-f7b6-8a4b2e63df26"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy : 97.83333333333333%\n"
          ]
        }
      ]
    }
  ]
}